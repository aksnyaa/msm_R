---
title: "Компьютерная работа 1"
author: "Группа 1"
date: "2025-03-16"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r message=FALSE, warning=FALSE}
library(knitr)
library(kableExtra)
library(magrittr)
library(openxlsx)
library(DescTools)
library(rio)
library(EnvStats)
library(outliers)
library(psych)
library(robustHD)
library(ggpubr)
library(ggplot2)
library(lmtest)
library(sjPlot)
library(GGally)
library(leaps)
library(questionr)
library(pander)
library(corrplot)
library(lmtest)
library(ppcor)
```

## Постановка задачи
1. Описание и обоснование системы показателей, обоснование репрезентативности выборки;

Работа направлена на анализ рынка ОСАГО в субъектах Российской Федерации с целью выявления и оценки масштабов мошеннических действий.

Зависимая переменная - скользящий коэффициент выплат, который рассчитывается как отношение страховых выплат к страховым премиям за анализируемый период (в %). 
Все данные, представленные в Таблице 1, являются относительными и взяты за периоды с 23 по 24 гг.

Количество наблюдений 85, как кол-во регионов в РФ, количество объясняющих переменных - 19. 

```{r}
desc <- read.xlsx('Данные_компраб1.xlsx', sheet = 'Data')
kbl(desc, caption = "Таблица 1. Описание данных", booktabs = T, 
    col.names = c("Переменная", "Описание переменной")) %>% 
  kable_classic_2(html_font = "Cambria", font_size = 10, full_width = F) %>%
  pack_rows("Зависимая переменная", 1, 1) %>%
  pack_rows("Показатели страхования", 2, 10) %>%
  pack_rows("Социальные показатели", 10, 18) %>%
  pack_rows("Погодные показатели", 19, 19) %>%
  pack_rows("Транспорт", 20, 20) %>%
  pack_rows("Прочее", 21, 21)
```

Объянсяющие переменные были разделены на
1. показатели страхования, которые могут быть напрямую связаны с зависимой переменной
2. социальные показатели, которые также могут оказывать влияние на ценообразование
3. погодные показатели и транспорт, которые также могут влиять на количество пользователей ОСАГО, вероятность страховых случаев.

Данные были сформированы на основе следующих источников данных:
1. https://autoins.ru/osago/regions-ranking/

2. https://www.cbr.ru/insurance/

3. https://riarating.ru/infografika/20240122/630256247.html

4. http://rosstat.gov.ru/

#### Выдвижение рабочих гипотез исследования

Сильная зависимость скользящего коэффициента выплат от показателей страхования и более слабая от социальных, погодных и транспортных переменных.
Возможны аномальные наблюдения в связи с сильным соц-эк неравенством регионов. 

## Основные характеристики СВ - только для зависимой переменной

```{r}
df <- read.xlsx('Данные_компраб1.xlsx', sheet = 'Данные для КА', startRow = 2)
head(df)
```

Посмотрим на общую структуру данных:

```{r}
str(df)
```

Наблюдения (строки): 85
Переменные (столбцы): 21
Все объясняющие переменные в датасете имеют тип num, то есть числовой.

#### Характеристики положения исследуемой СВ - скользящего коэффициента выплат (MovAvgCR).

```{r}
paste('Среднее: ', round(mean(df$MovAvgCR), 3))
paste('Медиана: Me = ', median(df$MovAvgCR))
paste('Мода: Mo = ', Mode(df$MovAvgCR))
```

Значения среднего (0.642) немного выше медианы (0.572), что может указывать на небольшой скос справа. Распределение данных близко к симметричному. 

####  Характеристики разброса СВ

```{r}
paste('min = ', range(df$MovAvgCR)[1])
paste('max = ', range(df$MovAvgCR)[2])
paste('Размах: R = max - min = ', round(range(df$MovAvgCR)[2] - range(df$MovAvgCR)[1], 3))
paste('Коэффициент вариации: CV = ', round(CoefVar(df$MovAvgCR)*100, 3), '%')
paste('Дисперсия: Var(MovAvgCR) = ', round(var(df$MovAvgCR), 3))
paste('Стандартное отклонение: sd(MovAvgCR) = ', round(sd(df$MovAvgCR), 3))
```

Размах (R = 2.407) говорит о том, что значения переменной сильно различаются между минимальным и максимальным значением.Также коэффициент вариации (CV = 44.642%) достаточно высокий, что указывает на то, что данные сильно разбросаны относительно среднего значения и переменная не однородная. Дисперсия (Var = 0.082) и стандартное отклонение (sd = 0.287) тоже показывают, что данные не сконцентрированы вокруг среднего.
Переменная MovAvgCR имеет большой разброс значений. Это означает, что данные неоднородны, и значения могут сильно отличаться друг от друга.

#### Ранговые характеристики СВ

Границы квартильных групп и децили:

```{r}
pander(quantile(df$MovAvgCR))
quantile(df$MovAvgCR, seq(from = 0, to = 1, by = 0.1))
```

Данные переменной MovAvgCR имеют умеренный разброс вокруг медианы, хотя общий диапазон значений широк. Q1 (0.5139) ближе к медиане (0.572), чем Q3 (0.659), распределение, вероятно, имеет лёгкий перекос вправо и может содержать выбросы среди больших значений.

## Диагностика выбросов

```{r}
paste('Интерквартильный размах: IQR = Q3 - Q1 = ', IQR(df$MovAvgCR))
```

##### Применение правила 3σ (трёх сигм)

```{r}
mean_value <- mean(df$MovAvgCR, na.rm = TRUE)
sd_value <- sd(df$MovAvgCR, na.rm = TRUE)

lower_bound <- mean_value - 3 * sd_value
upper_bound <- mean_value + 3 * sd_value

outliers_3sigma <- df$MovAvgCR[df$MovAvgCR < lower_bound | df$MovAvgCR > upper_bound]
outliers_3sigma
```

Номера нетипичных наблюдений:

```{r}
outliers_3sigma_indices <- which(df$MovAvgCR < lower_bound | df$MovAvgCR > upper_bound)
outliers_3sigma_indices
```

Имеется 2 нетипичных наблюдения.

##### Применение правила 1.5IQR для диагностики выбросов

```{r}
MovAvgCR_sorted <- sort(df$MovAvgCR)

out_of_1.5IQR <- boxplot.stats(df$MovAvgCR)$out
out_of_1.5IQR
```

Номера нетипичных наблюдений:

```{r}
out_of_1.5IQR_ind <- which(MovAvgCR_sorted %in% out_of_1.5IQR)
out_of_1.5IQR_ind
```

Имеется одно нетипичное наблюдение в начале и 8 в конце.

##### Применение правила 3IQR для диагностики экстремальных выбросов

```{r}
out_of_3IQR <- boxplot.stats(df$MovAvgCR, coef = 3)$out
out_of_3IQR
```

Номера нетипичных наблюдений:

```{r}
out_of_3IQR_ind <- which(MovAvgCR_sorted %in% out_of_3IQR)
out_of_3IQR_ind
```

Четыре нетипичных наблюдения в конце.

Нетипичные наблюдения на конце могли привести к асимметрии вправо, замеченной ранее.
Продолжим анализ, чтобы убедиться, нужно ли исключать эти наблюдения из выборки.

#### Построение ящичковой диаграммы

```{r}
boxplot(df$MovAvgCR, main = "Распределение MovAvgCR", ylab = "MovAvgCR")
```

Действительно, распределение имеет перекос вправо, так как верхний "ус" длиннее нижнего, а выбросы находятся вверху. Имеется одно наблюдение, сильно выделяющееся от остальных, в верхней части. Медиана смещена вниз. В целом, распределение MovAvgCR характеризуется высокой плотностью значений в центральном диапазоне, но присутствуют значительные выбросы, особенно в сторону увеличения. Возможна правосторонняя асимметрия.

#### Проверка гипотезы о наличии аномальных наблюдений с помощью критерия Рознера

Так как имеется несколько нетипичных наблюдений, для проверки используем тест Рознера.

Нулевая гипотеза ($H_0$):
Все наблюдения (включая $k$ наибольших) взяты из одной и той же генеральной совокупности. То есть выбросов нет.
Альтернативная гипотеза ($H_1$):
По крайней мере одно из $k$ наибольших наблюдений является выбросом и не принадлежит той же генеральной совокупности, что и остальные данные.
Для 1.5IQR $k = 9$ (наибольшее значение).

```{r}
k = length(out_of_1.5IQR_ind)
pander(rosnerTest(df$MovAvgCR, k = k)$all.stats)
```

Результат теста Рознера показывает, что первые 6 наблюдений (с индексами 51, 81, 50, 22, 44, 83) являются выбросами. Высокие значения (2.576, 1.515, 1.37, 1.115, 1.052) значительно превышают среднее и могут быть результатом редких событий. Низкое значение (0.1697) значительно ниже среднего и также может быть выбросом. Гипотеза $H_0$ отвергается.

Можем исключить эти данные и построить заново ящик с усами.

```{r}
outlier_indices <- c(51, 81, 50, 22, 44, 83)
df_cleaned <- df[-outlier_indices, ]
boxplot(df_cleaned$MovAvgCR, main = "Распределение MovAvgCR без выбросов", ylab = "MovAvgCR")
```

```{r}
k = 4
pander(rosnerTest(df_cleaned$MovAvgCR, k = k)$all.stats)
```

Нетипичные наблюдения на новом графике не являются выбросами.

После удаления выбросов распределение переменной MovAvgCR стало более симметричным и однородным. Разброс данных сократился, что делает дальнейший анализ более устойчивым.

## Проверка соответствия эмпирического распределения нормальному закону

**1. Расчёт коэффициентов асимметрии и эксцесса**

Ранее мы выдвигали предположение о правосторонней ассиметрии.

```{r}
paste('Коэффициент асимметрии: As = ', round(Skew(df$MovAvgCR), 3))
paste('Коэффициент эксцесса: Ek = ', round(Kurt(df$MovAvgCR), 3))
```

Коэффициент ассиметрии =0,5 < 4.149  - существенная правосторонняя ассиметрия.
Коэффициент эксцесса = 0 < 23.19  => островершинное распределение.

**2. Построение гистограммы распределения**

```{r, warning = FALSE, message = FALSE}
ggplot(df, aes(x = (df$MovAvgCR))) + 
  geom_histogram(color = "black", fill = "lightblue") + 
  ylab("Относительная частота") +
  xlab("MovAvgCR")
```

По гистограмме мы видим ранее отмеченную ассиметрию с хвостом справа, т.е. ненормальным.

```{r, warning = FALSE, message = FALSE}
ggplot(df, aes(x = log(df$MovAvgCR))) + 
  geom_histogram(color = "black", fill = "lightblue") + 
  ylab("Относительная частота (log)") +
  xlab("MovAvgCR")
```

При логарифмировании график становится более симметричным и похожим на нормальное распределение. Но мешают видимые аномальные значение.

Построим гистограмму для очищенных данных:
```{r, warning = FALSE, message = FALSE}
ggplot(df_cleaned, aes(x = df_cleaned$MovAvgCR)) + 
  geom_histogram(color = "black", fill = "lightblue") + 
  ylab("Относительная частота очищенные данные") +
  xlab("MovAvgCR")
```

Здесь мы видим лучшее распределение, но все равно есть асимметрия.

И для логарифмированных:

```{r, warning = FALSE, message = FALSE}
ggplot(df_cleaned, aes(x = log(df_cleaned$MovAvgCR))) + 
  geom_histogram(color = "black", fill = "lightblue") + 
  ylab("Относительная частота очищенные данные") +
  xlab("MovAvgCR")
```

Полученная гистограмма наиболее напоминает график нормального распределения. 

**3. Проверка гипотезы о нормальном распределении совокупности с использованием статисти- ческого критерия (критерий Пирсона, Колмогорова и т.д.) **

**Тест Шапиро-Уилка:**

```{r}
pander(shapiro.test(df$MovAvgCR))
pander(shapiro.test(log(df$MovAvgCR)))
pander(shapiro.test(df_cleaned$MovAvgCR))
pander(shapiro.test(log(df_cleaned$MovAvgCR)))
```

Все полученные значения p-value < 0,05 => отвергается принадлежность к нормальному распределению.
Тем не менее p-value у логарифмированных очищенных данных близко к 0.05 и при другом заданном а смогут считаться нормальными.

**Тест Пирсона:**

Проведем тест для очищенных данных и для них же в предположении, что они подчиняются логарифмическому распределению. 
```{r}
pander(PearsonTest(df_cleaned$MovAvgCR))
pander(PearsonTest(log(df_cleaned$MovAvgCR)))
```
В первом случае P-value меньше 5%.
Во втором случае P-value больше выбранного уровня значимости 5%, значит, нулевая гипотеза о нормальности распределения не отвергается для логарифмированного распределения.


**Тест Колмогорова-Смирнова:**

Проведем тест для очищенных данных и для них же в предположении, что они подчиняются логарифмическому распределению. 

```{r}
pander(ks.test(df_cleaned$MovAvgCR, 'pnorm', mean(df_cleaned$MovAvgCR), sd(df_cleaned$MovAvgCR)))
pander(ks.test(log(df_cleaned$MovAvgCR), 'pnorm', mean(log(df_cleaned$MovAvgCR)), sd(log(df_cleaned$MovAvgCR))))
```

P-value больше выбранного уровня значимости 5% в обоих случаях, значит, нулевая гипотеза о нормальности распределения не отвергается.

Таким образом, по проведенным тестам можно сделать вывод, что распределение логарифмическое.

**4. Выводы**

Исходные данные не подчиняются нормальному распределению, что видно по гистограмме и получается в тестах на нормальность распределения. 
Только 1 тест показал, что распределение без аномальных наблюдений является нормальным.
И все тесты, а также гистограмма показали, что очищенные данные подчиняются логарифмическому распределению. 

## Корреляционный анализ

Перед началом корреляционного анализа стоит отметить возможную погрешность, из-за того, что не все переменные выборки принадлежат к нормальному распределению.

### Построение облака (поля) корреляции 

#### Положительная зависимость до и после удаления выбросов

```{r}
ggscatter(df, x = "RepeatLossPct", y = "MovAvgCR", 
          xlab = "Индикатор выборки по признаку «неоднократности убытков»", ylab = "Скользящий коэффициент выплат")
ggscatter(df_cleaned, x = "RepeatLossPct", y = "MovAvgCR", 
          xlab = "Индикатор выборки по признаку «неоднократности убытков»", ylab = "Скользящий коэффициент выплат")
```

На диаграмме рассеяния можно заметить, что значения сгруппированы между собой. Кроме того, скользящий коэффициент выплат увеличивается с увеличением индикатора выборки по признаку "неоднократности убытков".

#### Обратная зависимость до и после удаления выбросов

```{r}
ggscatter(df, x = "MinCBMPct", y = "MovAvgCR", 
          xlab = "Доля водителей с минимальным значением КБМ", ylab = "Скользящий коэффициент выплат")
ggscatter(df_cleaned, x = "MinCBMPct", y = "MovAvgCR", 
          xlab = "Доля водителей с минимальным значением КБМ", ylab = "Скользящий коэффициент выплат")
```

На этой диаграмме рассеяния тоже можно заметить, что значения сгруппированы между собой, а скользящий коэффициент выплат уменьшается с увеличением доли водителей с минимальным значением КБМ.

#### Отсутствие зависимости на диаграмме рассеяния до и после удаления выбросов

```{r}
ggscatter(df, x = "SettledAppealRatio", y = "MovAvgCR", 
          xlab = "Коэффициент урегулированных обращений", ylab = "Скользящий коэффициент выплат")
ggscatter(df_cleaned, x = "SettledAppealRatio", y = "MovAvgCR", 
          xlab = "Коэффициент урегулированных обращений", ylab = "Скользящий коэффициент выплат")
```

На диаграмме рассеяния можно заметить, что значения разбросаны и не имеют связи между собой. 

### Построение и интерпретация матрицы парных коэффициентов корреляции

Перед этим исключим от переменные с коэффициентом корреляции выше |0.8|, чтобы избавиться от проблемы мультиколлинеарности:

```{r}
df2 <- df[, 2:21]
cor_m1 <- cor(df2, method = "pearson")
df2_cleaned <- df_cleaned[, 2:21]
df2_cleaned1 <- df2_cleaned
df2_cleaned <- df2_cleaned[, -3]
df2_cleaned <- df2_cleaned[, -8]
df2_cleaned <- df2_cleaned[, -10]
df2_cleaned <- df2_cleaned[, -13]
cor_m2 <- cor(df2_cleaned, method = "pearson")
cor_m2_to_check <- cor(df2_cleaned1, method = "pearson")
corrplot(as.matrix(cor_m1), type = "full", method = "circle", tl.col = "black", tl.srt = 45, tl.cex = 0.5)
corrplot(as.matrix(cor_m2_to_check), type = "full", method = "circle", tl.col = "black", tl.srt = 45, tl.cex = 0.5)
```

Сравнивая изначальную выборку с той, которая получилась после удаления выбросов, можно заметить, что в основном коэффициент парной корреляции для очищенной выборки по модулю стал меньше, в этом можно убеедиться посмотрев на матрицу ниже.

```{r}
 cor_dif = abs(cor_m2_to_check) - abs(cor_m1) 
 sorted_values <- sort(cor_dif, decreasing = TRUE)
 corrplot(as.matrix(cor_dif), type = "full", method = "circle", tl.col = "black", tl.srt = 45, tl.cex = 0.5)
```

Проверим значимости коэффициентов парной корреляции для изначальной выборки и выборки без аномальных значений и без проблемы мультиколлинеарности.

```{r}
cor_sign <- cor.mtest(df2, conf.level = 0.95)
cor_sign_c <- cor.mtest(df2_cleaned, conf.level = 0.95)
cor_sign_c_wm <- cor.mtest(df2_cleaned1, conf.level = 0.95)
corr_mat <- corrplot(cor(df2), p.mat = cor_sign$p, sig.level = 0.05, lowCI.mat = cor_sign$lowCI, uppCI.mat = cor_sign$uppCI)
corr_mat_c <- corrplot(cor(df2_cleaned), p.mat = cor_sign_c$p, sig.level = 0.05)
```

Построим большую таблицу, в которой будет точечная оценка коэффициента корреляции, нижний интервал, верхний интервал, p-value:

```{r}
results <- data.frame(
  Correlation = as.vector(cor_m1),
  LrCI = as.vector(cor_sign$lowCI),
  UCI = as.vector(cor_sign$uppCI),
  P = as.vector(cor_sign$p)
)
var_names <- expand.grid(rownames(cor_m1), colnames(cor_m1))
results <- cbind(Var1 = var_names$Var1, Var2 = var_names$Var2, results)
results$pair <- apply(results[, c("Var1", "Var2")],1, function(x) paste(sort(x), collapse = "-"))
results_unique <- results[!duplicated(results$pair), ]
results_final <- results_unique[results_unique$Var1 != results_unique$Var2, ]
results_final
table(results_final$P <= 0.05)
```

```{r}
results_wm <- data.frame(
  Correlation = as.vector(cor_m2_to_check),
  LrCI = as.vector(cor_sign_c_wm$lowCI),
  UCI = as.vector(cor_sign_c_wm$uppCI),
  P = as.vector(cor_sign_c_wm$p)
)
var_names_wm <- expand.grid(rownames(cor_m2_to_check), colnames(cor_m2_to_check))
results_wm <- cbind(Var1 = var_names_wm$Var1, Var2 = var_names_wm$Var2, results_wm)
results_wm$pair <- apply(results_wm[, c("Var1", "Var2")],1, function(x) paste(sort(x), collapse = "-"))
results_unique_wm <- results_wm[!duplicated(results_wm$pair), ]
results_final_wm <- results_unique_wm[results_unique_wm$Var1 != results_unique_wm$Var2, ]
results_final_wm
table(results_final_wm$P <= 0.05)
```

Первая таблица показывает интервалы и значимость для изначальной выборки, а вторая для очищенных данных. Как можно заметить, количество значимых коэффициентов значимости уменьшилось после удаления аномальных значений.

```{r}
results_c <- data.frame(
  Correlation = as.vector(cor_m2),
  LrCI = as.vector(cor_sign_c$lowCI),
  UCI = as.vector(cor_sign_c$uppCI),
  P = as.vector(cor_sign_c$p)
)
var_names_c <- expand.grid(rownames(cor_m2), colnames(cor_m2))
results_c <- cbind(Var1 = var_names_c$Var1, Var2 = var_names_c$Var2, results_c)
results_c$pair <- apply(results_c[, c("Var1", "Var2")],1, function(x) paste(sort(x), collapse = "-"))
results_unique_c <- results_c[!duplicated(results_c$pair), ]
results_final_c <- results_unique_c[results_unique_c$Var1 != results_unique_c$Var2, ]
results_final_c
table(results_final_c$P <= 0.05)
```

Эта таблица показывает оценки парного коэффициентта корреляции для очищенных данных (без аномальных значений и без проблемы мультиколлинеарности), для неё отношение значимых коэффициентов к незначимым уменьшилось ещё сильнее.

### Матрица частных коэффициентов корреляции

```{r}
cor_p <- pcor(scale(df2_cleaned))
cor_c_p <- kbl(caption = "Матрица частных коэффициентов корреляции", cor_p$estimate, booktabs = T) %>% 
 kable_classic(html_font = "Cambria")
cor_c_p
```

Бросается в глаза высокая средняя обратная зависимость между зависимой переменной и индикатором выборки, но самой интересной для нашего исследования является средняя прямая связь между средней заработной платой и количеством тяжких и особо тяжких преступлений. Далее, хотелось бы упомянуть довольно очевидную обратную связь между ожидаемой продолжительностью жизни и количеством тяжелых преступлений. 

```{r}
corpr_sign <- cor.mtest(cor_p$estimate, conf.level = 0.05)
```

```{r}
results_c_p <- data.frame(
  Correlation = as.vector(cor_p$estimate),
  LrCI = as.vector(corpr_sign$lowCI),
  UCI = as.vector(corpr_sign$uppCI),
  P = as.vector(corpr_sign$p)
)
var_names_c_p <- expand.grid(rownames(cor_p$estimate), colnames(cor_p$estimate))
results_c_p <- cbind(Var1 = var_names_c_p$Var1, Var2 = var_names_c_p$Var2, results_c_p)
results_c_p$pair <- apply(results_c_p[, c("Var1", "Var2")],1, function(x) paste(sort(x), collapse = "-"))
results_unique_c_p <- results_c_p[!duplicated(results_c_p$pair), ]
results_final_c_p <- results_unique_c_p[results_unique_c_p$Var1 != results_unique_c_p$Var2, ]
results_final_c_p
table(results_final_c_p$P <= 0.05)
```

Как мы видим, только два частных коэффициента корреляции оказались значимыми с вероятностью ошибки 0.05.

### Сравнение парных и частных коэффициентов корреляции

Сравним парные и частные коэффициенты корреляции для выборок без аномальных наблюдений.

```{r}
corrplot(as.matrix(cor_m2), type = "full", method = "circle", tl.col = "black", tl.srt = 45, tl.cex = 0.5)
corrplot(as.matrix(cor_p$estimate), type = "full", method = "circle", tl.col = "black", tl.srt = 45, tl.cex = 0.5)
corrplot(as.matrix(abs(cor_m2)-abs(cor_p$estimate)), type = "full", method = "circle", tl.col = "black", tl.srt = 45, tl.cex = 0.5)
```

Для большинства переменных характерно небольшое различие между парным и частными коэффициенами корреляции, однако есть несколько интересных случаев, например, для Средней заработной платы за 2023 год и Доли водителей с минимальным знанием КБМ очевидна разница между парным и частными коэффициентами корреляции, что свидетельствует о ложной корреляции.

### Построение множественного коэффициента корреляции

```{r}
clean_mat <- as.matrix(cor_m2)
det_mat <- det(clean_mat) 
A <- (-1) ^ 2 * det(clean_mat[-1, -1]) 
R <- sqrt(1 - (det_mat / A))
R
Fнабл <- (1/19*R^2)/(1/(79-20)*(1-R^2))
F_critical <- qf(0.95,19,59)
Fнабл
F_critical
```

Наблюдаемое значение статистики гораздо больше критического, поэтому можно считать множественный коэффициент корреляции значимым.Значение множественного коэффициента корреляции говорит о сильной линейной зависимости между скользящим коэффициентом выплат и факторными переменными.

### Регрессионный анализ. Линейная регрессионная модель

Построим линейную модель с учётом всех факторов без категориальных переменных (в данном случае исключаем фактор регион).

```{r}
llm1 <- lm(MovAvgCR ~ ., df2_cleaned)
summary(llm1)
```

Объясняющая способность модели высокая, Р-квадрат равен 0.79. Наиболее значимыми факторами оказались статистические показатели, что подтверждает гипотезу о сильной связи факторов в страховании и целевой переменной.

Оптимизируем модель, постепенно исключая наименее значимые факторы (выбор производится по наибольшему p-value).

```{r}
df2_optimized <- df2_cleaned[,-4]

llm2 <- lm(MovAvgCR ~., df2_optimized)
summary(llm2)
```

После удаления показателя отношения судебных решений к несудебным объясняющая способность R^2 adjusted модели выросла. Продолжаем оптимизацию.

```{r}
df2_optimized1 <- df2_optimized[,-10]
llm3 <- lm(MovAvgCR ~., df2_optimized1)
summary(llm3)
```

Р-квадрат adjusted возрос. Продолжим процесс элиминации незначимых факторов:

```{r}
df2_optimized2 <- df2_optimized1[,-13]
llm4 <- lm(MovAvgCR ~., df2_optimized2)
summary(llm4)
```

Снова видим увеличение Р-квадрат.

```{r}
df2_optimized3 <- df2_optimized2[,-9]
llm5 <- lm(MovAvgCR ~., df2_optimized3)
summary(llm5)
```

```{r}
df2_optimized4 <- df2_optimized3[,-5]
llm6 <- lm(MovAvgCR ~., df2_optimized4)
summary(llm6)
```

```{r}
df2_optimized5 <- df2_optimized4[,-8]
llm7 <- lm(MovAvgCR ~., df2_optimized5)
summary(llm7)
```

После удаления фактора уровня образования Adjusted R^2 снизился, объясняющая способность модели упала. Будем считать предыдущую модель оптимальной (llm6). Коэффициент детерминации равен 0.75, то есть три четверти вариации выборки объясняется моделью. Два коэффициента (число водителей с минимальным КБМ, индикатор выборки по признаку неоднократных убытков) значимы на уровне 0.001, три коэффициента (частота страховых случаев, коэффициент урегулированных обращений и средняя зарплата) являются значимыми на уровне 0.01, один коэффициент (отношение судебных расходов к сумме основного требования) значим на уровне 0.05.
 
Построим график наблюдаемых и модельных значений для выбранной модели.

```{r, warning = FALSE}
predoptimum <- predict(llm6)
ggplot(df2_optimized4, aes(x = seq(1, nrow(df2_optimized4), 1), y = df2_optimized4$MovAvgCR)) + 
  geom_point(color = "blue") + 
  geom_line(aes(x = seq(1, nrow(df2_optimized4), 1), y = predoptimum)) +
  labs(x = "Номер наблюдения", y = "Скользящий коэффициент выплат")
```

Некоторые предсказанные значения отличаются от фактических, это следует из объясняющей способности модели. Проверим нормальность остатков.

```{r}
pander(shapiro.test(llm6$residuals))
```

На уровне значимости 0.0004 остатки следуют нормальному распределению. 

Интерпретируем полученные коэффициенты: коэффициент при тяжких и особо тяжких преступлениях и частоте страховых случаев больше нуля, то есть при увеличении тяжких и особо тяжких преступлений на одно коэффициент выплат повышается на 0.001554, при повышении частоты страховых случаев коэффициент выплат увеличивается на 4.851937, при увеличении среднего числа машин (на 1000 человек) на одну машину средний скользящий коэффициент повышается на 0.000169, при повышении коэффициента урегулированных обращений на единицу коэффициент выплат повышается на 1.729900, при повышении отношения судебных расходов к требованиям коэффициент выплат возрастает на 0.019173, при увеличинении индикатора неоднократности убытков коэффициент выплат увеличивается на 0.0224165.

При повышении региона в рейтинге соц-эк развития на одно место коэффициент выплат снижается на 0.0008542, при повышении среднего уровня зарплат на рубль коэффициент выплат снижается на 0.0000013, при увеличении доли водителей с минимальным КБМ на % коэффициент выплат понижается на -0.5684133, при повышении уровня образования на единицу коэффициент выплат понижается на 0.00143886.

Связь коэффициента выплат и числа тяжких и особо тяжких преступлений можно объяснить тем, что более инфраструктурно развитым регионам свойственна низкая преступность. Водители в таких регионах попадают в меньше число аварий в виду развитой инфраструктуры. О похожей ситуации можно судить в случае числа машин на тысячу населения: чем больше машин, тем более должна быть развита инфраструктура в регионе и тем меньше страховых случаев должно происходить. Сюда же, к коэффициентам, отображающим благосостояние региона отнесём положение региона в рейтинге соц-эк развития, уровень образования и показатель средних зарплат.

Связь коэффициента выплат с частотой страховых случаев является очевидной: чем чаще происходят страховые случаи (аварии), тем больше выплат по контрактам производит страховая компания. 

Связь числа водителей с минимальным КБМ тоже вполне очевидна, наиболее опытные и осторожные водители получают низкий КБМ, следовательно они реже попадают в аварии и страховой фирме приходится реже исполнять обязательства.

Связь индикатора выборки по признаку неоднократных убытков со скользящим коэффициентом объясняется повышением числа выплат страховой компанией по обязательствам, если много пользователей страховки несколько раз попадают в аварии (страховые случаи), страховой фирме требуется больше денег тратить на выплаты.

Коэффициент урегулированных отношений также отображает эффективность фирмы по отказам по страховым случаям, если фирме получается отклонить обращение, выплат по контракту не происходит.

$MovAvgCR = -1.023 + 4.851937\cdot ClaimFreqPct-0.5684133 \cdot MinCBMPct+0.019173\cdot JudExpClaimRatioPct+1.729900 \cdot SettledAppealRatio + 0.001554\cdot SevereCrimeRate2023 + 0.0224165\cdot RepeatLossPct-0.0008542 \cdot SocEconRank2023-0.0000013\cdot AvgSalary2023+0.000169\cdot CarsPer1kPop2023 - 0.00143886\cdot EducationLevel2021$

### Регрессионный анализ. Нелинейная регрессионная модель

Перейдем к построению нелинейных регрессионных моделей. 

Для начала рассмотрим экспоненциальную модель. 

Прологарифмируем полученные после корреляционного анализа данные, и на их основе построим первую регрессионную модель.

```{r}
df_cleaned_exp <- df2_cleaned

df_cleaned_exp$MovAvgCR <- log(df2_cleaned$MovAvgCR)

df_cleaned_exp[abs(df_cleaned_exp) > 1000000000] <- 0


nllm1 <- lm(MovAvgCR ~ ., df_cleaned_exp)
summary(nllm1)
```

Видим, что объясняющая способность модели (Adjusted R-squared) довольно высокая - 75,63%, а также p-value F-статистики модели меньше любого разумного уровня значимости.

Теперь построим степенную модель, прологарифмировав отдельно каждый фактор.

```{r}
df_cleaned_pow <- df2_cleaned
df_cleaned_pow$MovAvgCR <- log(df2_cleaned$MovAvgCR)
df_cleaned_pow$MinCBMPct <- log(df2_cleaned$MinCBMPct)
df_cleaned_pow$`JudExpClaimRatioPct` <- log(df2_cleaned$`JudExpClaimRatioPct`)
df_cleaned_pow$SettledAppealRatio <- log(df2_cleaned$SettledAppealRatio)
df_cleaned_pow$SevereCrimeRate2023 <- log(df2_cleaned$SevereCrimeRate2023)
df_cleaned_pow$`RepeatLossPct` <- log(df2_cleaned$`RepeatLossPct`)
df_cleaned_pow$InjAccidentRate2023 <- log(df2_cleaned$InjAccidentRate2023)
df_cleaned_pow$LifeExpectancy2023 <- log(df2_cleaned$LifeExpectancy2023)
df_cleaned_pow$EducationLevel2021 <- log(df2_cleaned$EducationLevel2021)
df_cleaned_pow$`SocEconRank2023` <- log(df2_cleaned$`SocEconRank2023`)
df_cleaned_pow$AvgSalary2023 <- log(df2_cleaned$AvgSalary2023)
df_cleaned_pow$JanRainfall2023 <- log(df2_cleaned$JanRainfall2023)
df_cleaned_pow$CarsPer1kPop2023 <- log(df2_cleaned$CarsPer1kPop2023)
df_cleaned_pow$ClaimFreqPct <- log(df2_cleaned$ClaimFreqPct)
df_cleaned_pow$CrimCaseFiledPct <- log(df2_cleaned$CrimCaseFiledPct)
df_cleaned_pow$JudNonJudRatioPct <- log(df2_cleaned$JudNonJudRatioPct)

df_cleaned_pow[abs(df_cleaned_pow) > 1000000000] <- 0

nllm1_1 <- lm(MovAvgCR ~ ., df_cleaned_pow)
summary(nllm1_1)
```

Степенная модель имеет лучшую объясняющую способность в 75.92%, но при этом идентичное p-value, из чего мы можем сделать вывод о том, что степенная модель в данном случае лучше, чем экспоненциальная. 

Помимо этого, построим полиномиальную модель в предположении о зависимости главной переменной от индикатора выборки по признаку «неоднократности убытков».

```{r}
df3_cleaned <- df2_cleaned
df3_cleaned <- df3_cleaned[-which.max(df3_cleaned$RepeatLossPct),]
df3_cleaned$Repeat_2 <- df3_cleaned$`RepeatLossPct`^2

nllm1_2 <- lm(MovAvgCR ~ MinCBMPct + `JudExpClaimRatioPct` + SettledAppealRatio + SevereCrimeRate2023 + `RepeatLossPct` + InjAccidentRate2023 + LifeExpectancy2023 + EducationLevel2021 + `SocEconRank2023` + AvgSalary2023 +
                JanRainfall2023 + CarsPer1kPop2023 + ClaimFreqPct + Repeat_2, df3_cleaned)
summary(nllm1_2)
```

Полиномиальная модель, обладая тем же p-value, обладает большей объясняющей способностью (74.39 %).

Оптимизируем степенную модель, как модель с наибольшим показателем R adjusted. Поочередно исключим все факторы, имеющие наименьшую значимость, при этом наблюдая за объясняющей способностью модели (Adjusted R-squared).

```{r}
df_lm2 <- df_cleaned_pow[, -4]

nllm2 <- lm(MovAvgCR ~ ., df_lm2)
summary(nllm2)
```

```{r}
df_lm3 <- df_lm2[,-5]
llm3 <- lm(MovAvgCR ~., df_lm3)
summary(llm3)
```

```{r}
df_lm4 <- df_lm3[,-8]
nllm4 <- lm(MovAvgCR ~., df_lm4)
summary(nllm4)
```

```{r}
df_lm5 <- df_lm4[,-9]
nllm5 <- lm(MovAvgCR ~., df_lm5)
summary(nllm5)
```

```{r}
df_lm6 <- df_lm5[,-8]
nllm6 <- lm(MovAvgCR ~., df_lm6)
summary(nllm6)
```

```{r}
df_lm7 <- df_lm6[,-8]
nllm7 <- lm(MovAvgCR ~., df_lm7)
summary(nllm7)
```

При исключении фактора рейтинга соц-эк положения по итогам 2023 года объясняющая способность модели падает, поэтому остановим исключение факторов и выделим модель nllm6. У нее же adjusted R больше, чем у полиномиальной модели.

Теперь сравним графически теоретические частоты модели и фактические:

```{r, warning = FALSE}
predoptimum_log <- predict(nllm6)
ggplot(df_lm6, aes(x = seq(1, nrow(df_lm6), 1), y = df_lm6$MovAvgCR)) + 
  geom_point(color = "blue") + 
  geom_line(aes(x = seq(1, nrow(df_lm6), 1), y = predoptimum_log)) +
  labs(x = "Номер наблюдения", y = "Скользящий коэффициент выплат")
```

График модели довольно близок к фактическим частотам с незначительными отклонениями, что соответствует высокой объясняющей способности модели.

Проверим нормальность остатков:

```{r}
pander(shapiro.test(log(nllm6$residuals)))
```

Тест Шапиро-уилка также показывает, что гипотеза о неподчинении остатков нормальному распределению отвергается на уровне значимости 0.03.

Интерпретируем полученнные данные. 

Коэффициенты полученной модели показывают, что при повышении на условную единицу на уровне ошибки 0.03:

 - Частоты страховых случаев, скользящий коэффициент повысится на 0.30548
 - Доли водителей с минимальным значением КБМ, скользящий коэффициент понизится на 0.16623
 - Отношения судебных расходов к сумме основного требования, скользящий коэффициент повысится на 0.11742
 - Коэффициента урегулированных обращений, скользящий коэффициент повысится на 2.43509
 - Количества тяжких и особо тяжких преступлений в 2023 на 10 тыс. жителей, скользящий коэффициент выплат повысится на 0.15093
 - Индикатора выборки по признаку «неоднократности убытков», скользящий коэффициент повысится на 0.16042
 - Соц-эк рейтинга, скользящий коэффициент понизится на 0.08262
 - Среднемесячной номинальной начисленной заработной платы работников, скользящий коэффициент понизится на 0.16277
 - Количества осадков, скользящий коэффициент понизится на 0.03847
 - Количества собственных легковых автомобилей на 1000 человек населения, скользящий коэффициент повысится на 0.17719

Частота страховых случаев вполне логично повышает коэффициент выплат, ведь компания должна выплатить пострадавшему, тем самым повысив коэффициент

Доля водителей с минимальным значением КБМ понижает коэффициент, что может означать, что водители с минимальным КБМ больше отдают деньги страховым, нежели чем получают их в страховых случаях.

Отношение судебных расходов к сумме требования может показывать, что при более незначительных страховых взысканиях компания теряет больше, чем в случае более крупных случаев, что может быть связанно с различием страховых взносов в этих ситуациях.

Коэффициент урегулируемых обращений сильно повышает скользящий коэффициент, что говорит о невыгодности судебных сделок для страховых компаний. 

Неоднократность убытков от клиента ухудшает выгодность для фирмы, что в том числе повышает скользящий коэффициент выплат.

Повышение среднемесячной платы озночает повышенную платежеспособность клиента, а также клиент может покупать дополнительную страховку или же страховку на более дорогие товары, что повышает выгодность клиента для фирмы.

Количество осадков незначительно понижает коэффициент, на основе чего можно сделать предположение, что водители более аккуратны и внимательны при плохой погоде, тем самым уменьшая страховые случаи и повышая выгоду для фирмы.

Количество легковых автомобилей на 1000 человек населения может говорить о более сложных дорожных условиях для водителей, из-за чего страховые случаи могут участиться, понизив прибыль фирмы. 

Уравнение регрессии:

$log_MovAvgCR = 0.82666 + 0.30548\cdot log_ClaimFreqPct-0.16623 \cdot log_MinCBMPct+0.11742\cdot log_JudExpClaimRatioPct+2.43509 \cdot log_SettledAppealRatio + 0.15093\cdot log_SevereCrimeRate2023 + 0.16042\cdot log_RepeatLossPct-0.08262 \cdot log_SocEconRank2023-0.16277\cdot log_AvgSalary2023-0.03847\cdot log_JanRainfall2023+0.17719\cdot log_CarsPer1kPop2023$

## Сравнение регрессионных моделей

Используем информационный критерий Акаике и Шварца:

```{r}
IC_table <- data.frame(n = c('llm6', 'nllm6'),
                  a = rbind(AIC(llm6), AIC(nllm6)),
                  b = rbind(BIC(llm6), BIC(nllm6)))

kbl(IC_table,
    caption = "Таблица 1. Информационные критерии Акаике и Шварца (Баесовский инф. критерий)",
    booktabs = T, col.names = c("Модель", "Значение AIC", "Значение BIC")) %>%
    kable_classic(html_font = "Cambria", font_size = 12, full_width = F)
```

```{r}
IC_table2 <- data.frame(n = c('llm1', 'nllm1', 'nllm1_1', 'nllm1_2'),
                  a = rbind(AIC(llm1), AIC(nllm1), AIC(nllm1_1), AIC(nllm1_2)),
                  b = rbind(BIC(llm1), BIC(nllm1), BIC(nllm1_1), BIC(nllm1_2) ))
# информационный критерий Акаике
kbl(IC_table2,
    caption = "Таблица 1. Информационные критерии Акаике и Шварца (Баесовский инф. критерий)",
    booktabs = T, col.names = c("Модель", "Значение AIC", "Значение BIC")) %>%
    kable_classic(html_font = "Cambria", font_size = 12, full_width = F)
```

Выбор лучшей модели на основе инф критериев по их возрастанию, т.е. меньшее значения соответствует лучшей модели, такой моделью является llm6 - линейная модель с исключением незначимых переменных.

$MovAvgCR = -1.023 + 4.851937\cdot ClaimFreqPct-0.5684133 \cdot MinCBMPct+0.019173\cdot JudExpClaimRatioPct+1.729900 \cdot SettledAppealRatio + 0.001554\cdot SevereCrimeRate2023 + 0.0224165\cdot RepeatLossPct-0.0008542 \cdot SocEconRank2023-0.0000013\cdot AvgSalary2023+0.000169\cdot CarsPer1kPop2023 - 0.00143886\cdot EducationLevel2021$

Ее Adjusted R-squared =  0.7579 одно из самых больших из всех моделей.

Гипотезы подтвердились, хотя в модели не так много показателей страхования, т.к. многие из них были убраны на этапе построения модели из-за мультиколлинеарности, сильной связи с главной переменной.












